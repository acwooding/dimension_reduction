{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes we are running in notebooks\n",
    "root_dir = pathlib.Path(\"..\")\n",
    "\n",
    "hash_function = {\n",
    "    'sha1': hashlib.sha1,\n",
    "    'sha256': hashlib.sha256,\n",
    "    'md5': hashlib.sha256\n",
    "}\n",
    "\n",
    "def hash_file(fname, algorithm=\"sha1\", block_size=4096):\n",
    "    '''Compute the hash of an on-disk file\n",
    "    \n",
    "    algorithm: {'md5', sha1', 'sha256'}\n",
    "        hash algorithm to use\n",
    "    block_size:\n",
    "        size of chunks to read when hashing\n",
    "    \n",
    "    Returns:\n",
    "        Hashlib object\n",
    "    '''\n",
    "    hashval = hash_function[algorithm]()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(block_size), b\"\"):\n",
    "            hashval.update(chunk)\n",
    "    return hashval\n",
    "\n",
    "\n",
    "\n",
    "def fetch_file(url, raw_file=None, root_dir=None,\n",
    "               force=False, hash_type=\"sha1\", hash_value=None):\n",
    "    '''Fetch a remote file via URL\n",
    "    \n",
    "    url:\n",
    "        url to be downloaded\n",
    "    raw_file:\n",
    "        output file name. If not specified, use the last\n",
    "        component of the URL\n",
    "    root_dir:\n",
    "        root directory containing data dir\n",
    "    force: boolean\n",
    "        normally, the URL is only downloaded if `raw_file` is\n",
    "        not present on the filesystem, or if the existing file has a\n",
    "        bad hash. If force is True, a download is always attempted\n",
    "    hash_type:\n",
    "        Type of hash to compute\n",
    "    hash_value: (optional)\n",
    "        if specified, the hash of the downloaded file will be\n",
    "        checked against this value\n",
    "        \n",
    "    \n",
    "    returns one of:\n",
    "        (HTTP_Code, downloaded_filename, hash) (if downloaded from URL)\n",
    "        (True, filename, hash) (if already exists)\n",
    "        (False, [error]) \n",
    "    if `raw_file` already exists, compute the hash of the on-disk file,\n",
    "    '''\n",
    "    if root_dir is None:\n",
    "        root_dir = pathlib.Path(\".\")\n",
    "    if raw_file is None:\n",
    "        raw_file = url.split(\"/\")[-1]\n",
    "    raw_data_path = root_dir / 'data' / 'raw'\n",
    "    if not os.path.exists(raw_data_path):\n",
    "        os.makedirs(raw_data_path)\n",
    "\n",
    "    raw_data_file = raw_data_path / raw_file\n",
    "\n",
    "    if os.path.exists(raw_data_file):\n",
    "        raw_file_hash = hash_file(raw_data_file, algorithm=hash_type).hexdigest()\n",
    "        if hash_value is not None:\n",
    "            if raw_file_hash == hash_value:\n",
    "                if force is False:\n",
    "                    return True, raw_data_file, raw_file_hash\n",
    "            else:\n",
    "                print(f\"{raw_file} exists but has bad hash {raw_file_hash}.\"\n",
    "                      \" Re-downloading\")\n",
    "        else: # file exists but no hash to check\n",
    "            if force is False:\n",
    "                return True, raw_data_file, raw_file_hash\n",
    "\n",
    "    # Download the file\n",
    "    try:\n",
    "        results = requests.get(url)\n",
    "        results.raise_for_status()\n",
    "        raw_file_hash = hash_function[hash_type](results.content).hexdigest()\n",
    "        if hash_value is not None:\n",
    "            if raw_file_hash != hash_value:\n",
    "                print(f\"Invalid hash on downloaded {raw_file}\"\n",
    "                      f\" ({raw_file_hash}) != {hash_value}\")\n",
    "                return False, None, raw_file_hash \n",
    "        with open(raw_data_file, \"wb\") as code:\n",
    "            code.write(results.content)\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        return False, err, None\n",
    "\n",
    "    return results.status_code, raw_data_file, raw_file_hash\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_tgz(tgz_file, dst_dir=None):\n",
    "    '''Unpack a gzipped tarfile\n",
    "    \n",
    "    dst_dir: (default \".\")\n",
    "        destination directory for the unpack\n",
    "    '''\n",
    "    if dst_dir is None:\n",
    "        dst_dir = pathlib.Path(\".\")\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    tgz = tarfile.open(tgz_file, mode='r:gz')\n",
    "    tgz.extractall(path=dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_data_path = root_dir / 'data' / 'interim'\n",
    "processed_data_path = root_dir / 'data' / 'processed'\n",
    "\n",
    "datasets = {\n",
    "    'coil-100': ('http://www.cs.columbia.edu/CAVE/databases/SLAM_coil-20_coil-100/coil-100/coil-100.tar.gz',\n",
    " 'sha1', 'b58920394780e1c224a39004e74bd3574fbed85a')\n",
    "}\n",
    "\n",
    "for dataset_name, dataset_params in datasets.items():\n",
    "    url, hash_type, hash_value = dataset_params\n",
    "    status, file, hashval = fetch_file(url=url, root_dir=root_dir,\n",
    "                                       hash_type=hash_type,\n",
    "                                       hash_value=hash_value)\n",
    "    if status is True:\n",
    "        dst_dir = interim_data_path / dataset_name\n",
    "        unpack_tgz(file, dst_dir=dst_dir)\n",
    "    else:\n",
    "        print(\"Failed to download raw data: {}\", file)\n",
    "        print(status, file, hashval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dimension_reduction]",
   "language": "python",
   "name": "conda-env-dimension_reduction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
