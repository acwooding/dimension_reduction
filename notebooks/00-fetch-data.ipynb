{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, make sure you have activated the appropriate environment, and created the requisite datasets:\n",
    "```\n",
    "conda activate dimension_reduction\n",
    "make data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Datasets\n",
    "Look at the natural (non-synthetic) datasets that are available. This will fetch, process, and cache the datasets for use in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset: BALL\n",
      "Shape: data=(1000, 3), target=(1000,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: src.data.synthetic.sample_ball\n",
      "\n",
      ">>> sample_ball(1000, random_state=6502)\n",
      "\n",
      ">>> help(sample_ball)\n",
      "\n",
      "Sample from a unit ball\n",
      "\n",
      "    Use rejection sampling on the unit cube\n",
      "    \n",
      "============================================================\n",
      "Dataset: BROKEN-SWISS-ROLL\n",
      "Shape: data=(1000, 3), target=(1000,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: src.data.synthetic.synthetic_data\n",
      "\n",
      ">>> synthetic_data(kind='broken_swiss_roll', n_points=1000, noise=0.05, random_state=6502)\n",
      "\n",
      ">>> help(synthetic_data)\n",
      "\n",
      "Make a synthetic dataset\n",
      "\n",
      "    A sample dataset generators in the style of sklearn's\n",
      "    `sample_generators`. This adds other functions found in the Matlab\n",
      "    toolkit for Dimensionality Reduction\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    kind: {'unit_cube', 'broken_swiss_roll', 'twinpeaks', 'difficult'}\n",
      "        The type of synthetic dataset\n",
      "    n_points : int, optional (default=1000)\n",
      "        The total number of points generated.\n",
      "    noise : double or None (default=None)\n",
      "        Standard deviation of Gaussian noise added to the data.\n",
      "    random_state : int, RandomState instance or None (default)\n",
      "        Determines random number generation for dataset shuffling and noise.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "    Returns\n",
      "    -------\n",
      "    X : array of shape [n_points, 2]\n",
      "        The generated samples.\n",
      "    y : array of shape [n_points]\n",
      "        The labels for class membership of each point.\n",
      "\n",
      "    \n",
      "============================================================\n",
      "Dataset: COIL-100\n",
      "Shape: data=(7200, 49152), target=(7200,)\n",
      "============================================================\n",
      "\n",
      "Columbia University Image Library (COIL-100)\n",
      "============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 7200\n",
      "    :Number of Attributes: 49152\n",
      "    :Attribute Information: 128x128 image of 3 channels (16-bit RGB values)\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: Sameer A Nene, Shree K. Nayar and Hiroshi Murase\n",
      "    :Date: 1995\n",
      "\n",
      "This is a copy of the Columbia Object Image Library [COIL-100] data:\n",
      "http://www.cs.columbia.edu/CAVE/databases/SLAM_coil-20_coil-100/coil-100/coil-100.zip\n",
      "\n",
      "Columbia Object Image Library [COIL-100] is a database of color images of 100 objects.\n",
      "\n",
      "This dataset consists of 7,200 color images of 100 objects (72 images per object) where the objects\n",
      "have been placed on a motorized turntable against a black background. Images were taken at 5 degree rotations,\n",
      "giving 72 images per object. The resulting images were then size and intensity-normalized.\n",
      "\n",
      "Size normalization involved first clipping to a rectangual bounding box and resized (with aspect\n",
      "ratio preserved) to 128x128 using interpolation-decimation filters to minimize aliasing [Oppenheim and Schafer-1989].\n",
      "\n",
      "To normalize intensity, every image was histogram stretched, i.e. the intensity\n",
      "of the brightest pixel was made 65535 and intensities of the other pixels were scaled accordingly.\n",
      "The images were saved as 16-bit PPM (portable pixmap) color images.\n",
      "\n",
      "Raw data files are named according to object and rotation; e.g.  `obj7__10.ppm`.\n",
      "The prefix \"obj7\" identifies the object, and \"10\" indicates the rotation in degrees.\n",
      "\n",
      "A greyscale version of this dataset is also available: [COIL-20]\n",
      "\n",
      "References\n",
      "----------\n",
      "  - [COIL-100] Columbia Object Image Library (COIL-100), S. A. Nene, S. K. Nayar and H. Murase, \n",
      "    Technical Report CUCS-006-96, February 1996.\n",
      "    http://www.cs.columbia.edu/CAVE/databases/papers/nene/nene-nayar-murase-coil-100.ps.gz\n",
      "  - [COIL-20] S. A. Nene, S. K. Nayar and H. Murase. Columbia Object Image Library:\n",
      "    COIL-20. Technical Report CUCS-005-96, Department of Computer Science, Columbia\n",
      "    University, February 1996.\n",
      "    http://www.cs.columbia.edu/CAVE/databases/papers/nene/nene-nayar-murase-coil-20.ps.gz\n",
      "  - [Murase and Nayar, 1995] H. Murase and S. K. Nayar. Visual Learning and Recognition\n",
      "    of 3D Objects from Appearance. International Journal of Computer Vision , 14(1):5{24,\n",
      "    January 1995.\n",
      "  - [Nayar et al. , 1996b] S. K. Nayar, S. A. Nene and H. Murase. Real-Time 100 Object\n",
      "    Recognition System. In Proceedings of ARPA Image Understanding Workshop , Palm Springs,\n",
      "    February 1996.\n",
      "  - [Nayar et al. , 1996c] S. K. Nayar, S. A. Nene and H. Murase. Real-Time 100 Object\n",
      "    Recognition System. In Proceedings of IEEE International Conference on Robotics and\n",
      "    Automation , Minneapolis, April 1996.\n",
      "  - [Oppenheim and Schafer, 1989] A. V. Oppenheim and R. W. Schafer. Discrete-Time Signal\n",
      "    Processing , chapter 3, pages 111{130. Prentice Hall, 1989.\n",
      "\n",
      "\n",
      "============================================================\n",
      "Dataset: COIL-20\n",
      "Shape: data=(1440, 16384), target=(1440,)\n",
      "============================================================\n",
      "\n",
      "Columbia University Image Library (COIL-20)\n",
      "===========================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 1440\n",
      "    :Number of Attributes: 16384\n",
      "    :Attribute Information: 128x128 8-bit greyscale (PGM) image\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: Sameer A Nene, Shree K. Nayar and Hiroshi Murase\n",
      "    :Date: 1995\n",
      "\n",
      "This is a copy of the Columbia Object Image Library [COIL-20] data:\n",
      "http://www.cs.columbia.edu/CAVE/databases/SLAM_coil-20_coil-100/coil-20/coil-20-proc.tar.gz\n",
      "\n",
      "This dataset consists of 1,440 greyscale images of 20 objects (72\n",
      "images per object) where the objects have been placed on a motorized\n",
      "turntable against a black background. Images were taken at 5 degree\n",
      "rotations, giving 72 images per object. The resulting images were then\n",
      "size and intensity-normalized.\n",
      "\n",
      "Size normalization involved first clipping to a rectangual bounding\n",
      "box and resized (with aspect ratio preserved) to 128x128 using\n",
      "interpolation-decimation filters to minimize aliasing [Oppenheim and\n",
      "Schafer-1989].\n",
      "\n",
      "To normalize intensity, every image was histogram stretched, i.e. the\n",
      "intensity of the brightest pixel was made 255 and intensities of the\n",
      "other pixels were scaled accordingly.  The images were saved as 8-bit\n",
      "PGM (portable greymap) color images.\n",
      "\n",
      "Raw data files are named according to object and rotation; e.g.\n",
      "`obj7__10.pgm`.  The prefix \"obj7\" identifies the object, and \"10\"\n",
      "indicates the rotation in degrees.\n",
      "\n",
      "A color version of this library is also available: [COIL-100].\n",
      "\n",
      "References\n",
      "----------\n",
      "  - [COIL-20] S. A. Nene, S. K. Nayar and H. Murase. Columbia Object Image Library:\n",
      "    COIL-20. Technical Report CUCS-005-96, Department of Computer Science, Columbia\n",
      "    University, February 1996.\n",
      "  - [COIL-100] Columbia Object Image Library (COIL-100), S. A. Nene, S. K. Nayar and H. Murase, \n",
      "    Technical Report CUCS-006-96, February 1996.\n",
      "    http://www.cs.columbia.edu/CAVE/databases/papers/nene/nene-nayar-murase-coil-100.ps.gz\n",
      "  - [Murase and Nayar, 1995] H. Murase and S. K. Nayar. Visual Learning and Recognition\n",
      "    of 3D Objects from Appearance. International Journal of Computer Vision , 14(1):5{24,\n",
      "    January 1995.\n",
      "  - [Oppenheim and Schafer, 1989] A. V. Oppenheim and R. W. Schafer. Discrete-Time Signal\n",
      "    Processing , chapter 3, pages 111{130. Prentice Hall, 1989.\n",
      "\n",
      "\n",
      "============================================================\n",
      "Dataset: DIFFICULT\n",
      "Shape: data=(7776, 10), target=(7776,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: src.data.synthetic.synthetic_data\n",
      "\n",
      ">>> synthetic_data(kind='difficult', n_points=6000, noise=0.02, random_state=6502)\n",
      "\n",
      ">>> help(synthetic_data)\n",
      "\n",
      "Make a synthetic dataset\n",
      "\n",
      "    A sample dataset generators in the style of sklearn's\n",
      "    `sample_generators`. This adds other functions found in the Matlab\n",
      "    toolkit for Dimensionality Reduction\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    kind: {'unit_cube', 'broken_swiss_roll', 'twinpeaks', 'difficult'}\n",
      "        The type of synthetic dataset\n",
      "    n_points : int, optional (default=1000)\n",
      "        The total number of points generated.\n",
      "    noise : double or None (default=None)\n",
      "        Standard deviation of Gaussian noise added to the data.\n",
      "    random_state : int, RandomState instance or None (default)\n",
      "        Determines random number generation for dataset shuffling and noise.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "    Returns\n",
      "    -------\n",
      "    X : array of shape [n_points, 2]\n",
      "        The generated samples.\n",
      "    y : array of shape [n_points]\n",
      "        The labels for class membership of each point.\n",
      "\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset: F-MNIST\n",
      "Shape: data=(60000, 784), target=(60000,)\n",
      "============================================================\n",
      "\n",
      "MNIST\n",
      "=====\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 70000\n",
      "    :Number of Attributes: 728\n",
      "    :Attribute Information: 28x28 8-bit greyscale image\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: LeCun et al\n",
      "    :Date: 1998\n",
      "\n",
      "This is a copy of the well-known MNIST database of handwritten digits,\n",
      "available from http://yann.lecun.com/exdb/mnist/\n",
      "\n",
      "The MNIST database of handwritten digits consists of a training set of\n",
      "60,000 examples, and a test set of 10,000 examples. It is a subset of\n",
      "a larger set available from NIST. The digits have been size-normalized\n",
      "and centered in a fixed-size image.\n",
      "\n",
      "The original black and white (bilevel) images from NIST were size\n",
      "normalized to fit in a 20x20 pixel box while preserving their aspect\n",
      "ratio. The resulting images contain grey levels as a result of the\n",
      "anti-aliasing technique used by the normalization algorithm. the\n",
      "images were centered in a 28x28 image by computing the center of mass\n",
      "of the pixels, and translating the image so as to position this point\n",
      "at the center of the 28x28 field.\n",
      "\n",
      "\n",
      "References\n",
      "\n",
      "[LeCun et al., 1998a]  Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n",
      "\n",
      "============================================================\n",
      "Dataset: FREY-FACES\n",
      "Shape: data=(1965, 560), target=(1965,)\n",
      "============================================================\n",
      "\n",
      "Frey Faces\n",
      "==========\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 1965\n",
      "    :Number of Attributes: 560\n",
      "    :Attribute Information: 20x28 8-bit greyscale image\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: Roweis and Saul\n",
      "    :Date: 2000\n",
      "\n",
      "1965 images of Brendan Frey's face, taken from sequential frames of a\n",
      "small video. Size: 20x28.\n",
      "\n",
      "Note, there is no target data associated with this dataset, so it is\n",
      "of use mainly in unsupervised algorithms.\n",
      "\n",
      "The frey-faces dataset was first used in [RS2000] and is available from\n",
      "https://cs.nyu.edu/~roweis/data.html\n",
      "\n",
      "References\n",
      "----------\n",
      "[RS2000] Roweis, Sam T., and Lawrence K. Saul. \"Nonlinear dimensionality reduction by\n",
      "\t locally linear embedding.\" Science 290.5500 (2000): 2323-2326. \n",
      "\n",
      "============================================================\n",
      "Dataset: GAUSSIAN-BLOBS\n",
      "Shape: data=(1000, 10), target=(1000,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: sklearn.datasets.samples_generator.make_blobs\n",
      "\n",
      ">>> make_blobs(1000, centers=4, n_features=10, random_state=6502)\n",
      "\n",
      ">>> help(make_blobs)\n",
      "\n",
      "Generate isotropic Gaussian blobs for clustering.\n",
      "\n",
      "    Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n_samples : int, optional (default=100)\n",
      "        The total number of points equally divided among clusters.\n",
      "\n",
      "    n_features : int, optional (default=2)\n",
      "        The number of features for each sample.\n",
      "\n",
      "    centers : int or array of shape [n_centers, n_features], optional\n",
      "        (default=3)\n",
      "        The number of centers to generate, or the fixed center locations.\n",
      "\n",
      "    cluster_std : float or sequence of floats, optional (default=1.0)\n",
      "        The standard deviation of the clusters.\n",
      "\n",
      "    center_box : pair of floats (min, max), optional (default=(-10.0, 10.0))\n",
      "        The bounding box for each cluster center when centers are\n",
      "        generated at random.\n",
      "\n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Shuffle the samples.\n",
      "\n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    X : array of shape [n_samples, n_features]\n",
      "        The generated samples.\n",
      "\n",
      "    y : array of shape [n_samples]\n",
      "        The integer labels for cluster membership of each sample.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets.samples_generator import make_blobs\n",
      "    >>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n",
      "    ...                   random_state=0)\n",
      "    >>> print(X.shape)\n",
      "    (10, 2)\n",
      "    >>> y\n",
      "    array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    make_classification: a more intricate variant\n",
      "    \n",
      "============================================================\n",
      "Dataset: HELIX\n",
      "Shape: data=(1000, 3), target=(1000,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: src.data.synthetic.helix\n",
      "\n",
      ">>> helix(noise=0.05, random_state=6502)\n",
      "\n",
      ">>> help(helix)\n",
      "\n",
      "\n",
      "    Sample from a toroidal helix.\n",
      "\n",
      "    major_radius:\n",
      "        Major (equatorial) radius of the torus\n",
      "    minor_radius:\n",
      "        Minor (cross-section) radius of the torus\n",
      "    n_twists:\n",
      "        Number of twists in the toroidal helix\n",
      "    n_points:\n",
      "        Number of points to return\n",
      "    random_state: int or None\n",
      "        For seeding the random number generator\n",
      "    noise : double or None (default=None)\n",
      "        Standard deviation of Gaussian noise added to the data.\n",
      "\n",
      "\n",
      "    x = r_1 + r_2 cos(nt)) * cos(t)\n",
      "    y = r_1 + r_2 cos(nt)) * sin(t)\n",
      "    z = r_2 sin(nt)\n",
      "\n",
      "    where $n$ is `n_twists`, $r_1$ is the `major_radius`\n",
      "    and $r_2$ is the `minor_radius`\n",
      "\n",
      "    \n",
      "============================================================\n",
      "Dataset: HIVA\n",
      "Shape: data=(3845, 1617), target=(3845,)\n",
      "============================================================\n",
      "\n",
      "HIVA is a chemoinformatics dataset\n",
      "\n",
      "Data type: non-sparse\n",
      "Number of features: 1617\n",
      "Number of examples and check-sums:\n",
      "     \tPos_ex\tNeg_ex\tTot_ex\tCheck_sum\n",
      "Train\t  135\t 3710\t 3845\t564954.00\n",
      "Valid\t   14\t  370\t  384\t56056.00\n",
      "Test\t 1354\t37095\t38449\t5674217.00\n",
      "All  \t 1503\t41175\t42678\t6295227.0\n",
      "\n",
      "http://www.agnostic.inf.ethz.ch/datasets.php\n",
      "\n",
      "The task of HIVA is to predict which compounds are active against the\n",
      "AIDS HIV infection. The original data has 3 classes (active,\n",
      "moderately active, and inactive). We brought it back to a two-class\n",
      "classification problem (active vs. inactive). We represented the data\n",
      "as 1617 sparse binary input variables. The variables represent\n",
      "properties of the molecule inferred from its molecular structure. The\n",
      "problem is therefore to relate structure to activity (a\n",
      "QSAR=quantitative structure-activity relationship problem) to screen\n",
      "new compounds before actually testing them (a HTS=high-throughput\n",
      "screening problem).\n",
      "\n",
      "The original data were made available by The National Cancer Institute\n",
      "(USA). The 3d molecular structure was obtained by the CORINA software\n",
      "and the features were derived with the ChemTK software.  The HIVA\n",
      "dataset was used previously in the Performance Prediction challenge,\n",
      "the Model Selection game, and the Agnostic Learning vs. Prior\n",
      "Knowledge (ALvsPK) challenge. A variant of the HIVA dataset called\n",
      "SIDO was used in the Causation and Prediction challenge and the\n",
      "Pot-Luck challenge.\n",
      "\n",
      "\n",
      "============================================================\n",
      "Dataset: LVQ-PAK\n",
      "Shape: data=(3924, 20), target=(3924,)\n",
      "============================================================\n",
      "\n",
      "LVQ-PAK Phoneme Dataset\n",
      "=======================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 3924, optionally split into train (1962) and test (1962) sets\n",
      "    :Number of Attributes: 20\n",
      "    :Attribute Information: FFT coefficients\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: Teuvo Kohonen et al\n",
      "    :Date: 1995\n",
      "\n",
      "This is a copy of the [LVQ_PAK] phoneme dataset available as part of the LVQ-PAK\n",
      "software distrubution, available from:\n",
      "\n",
      "  http://www.cis.hut.fi/research/lvq_pak/\n",
      "\n",
      "The LVQ-PAK dataset consists of two data sets, training and testing\n",
      "respectively, each containing 1962 cepstral-coefficient vectors picked\n",
      "up from continuous Finnish speech, all from the same speaker.  Each\n",
      "vector has a dimensionality of 20 and has been labeled to represent\n",
      "one phoneme.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "[LVQ_PAK] Kohonen, Teuvo, et al. \"LVQ_PAK: A software package for the\n",
      "\t  correct application of learning vector quantization\n",
      "\t  algorithms.\"  Neural Networks, 1992. IJCNN., International\n",
      "\t  Joint Conference on. Vol. 1. IEEE, 1992.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset: MNIST\n",
      "Shape: data=(60000, 784), target=(60000,)\n",
      "============================================================\n",
      "\n",
      "MNIST\n",
      "=====\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 70000\n",
      "    :Number of Attributes: 728\n",
      "    :Attribute Information: 28x28 8-bit greyscale image\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: LeCun et al\n",
      "    :Date: 1998\n",
      "\n",
      "This is a copy of the well-known MNIST database of handwritten digits,\n",
      "available from http://yann.lecun.com/exdb/mnist/\n",
      "\n",
      "The MNIST database of handwritten digits consists of a training set of\n",
      "60,000 examples, and a test set of 10,000 examples. It is a subset of\n",
      "a larger set available from NIST. The digits have been size-normalized\n",
      "and centered in a fixed-size image.\n",
      "\n",
      "The original black and white (bilevel) images from NIST were size\n",
      "normalized to fit in a 20x20 pixel box while preserving their aspect\n",
      "ratio. The resulting images contain grey levels as a result of the\n",
      "anti-aliasing technique used by the normalization algorithm. the\n",
      "images were centered in a 28x28 image by computing the center of mass\n",
      "of the pixels, and translating the image so as to position this point\n",
      "at the center of the 28x28 field.\n",
      "\n",
      "\n",
      "References\n",
      "\n",
      "[LeCun et al., 1998a]  Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".Z files are only supported on systems that ship with gzip. Trying...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset: ORL-FACES\n",
      "Shape: data=(400, 10304), target=(400,)\n",
      "============================================================\n",
      "\n",
      "The ORL face database\n",
      "---------------------\n",
      "\n",
      "This directory contains a set of faces taken between April 1992 and\n",
      "April 1994 at the Olivetti Research Laboratory in Cambridge, UK.\n",
      "\n",
      "There are 10 different images of 40 distinct subjects. For some of the\n",
      "subjects, the images were taken at different times, varying lighting\n",
      "slightly, facial expressions (open/closed eyes, smiling/non-smiling)\n",
      "and facial details (glasses/no-glasses).  All the images are taken\n",
      "against a dark homogeneous background and the subjects are in\n",
      "up-right, frontal position (with tolerance for some side movement).\n",
      "\n",
      "The files are in PGM format and can be conveniently viewed using the 'xv'\n",
      "program. The size of each image is 92x112, 8-bit grey levels. The images\n",
      "are organised in 40 directories (one for each subject) named as:\n",
      "\n",
      "\t\tsX\n",
      "\n",
      "where X indicates the subject number (between 1 and 40). In each directory\n",
      "there are 10 different images of the selected subject named as:\n",
      "\n",
      "\t\tY.pgm\n",
      "\n",
      "where Y indicates which image for the specific subject (between 1 and 10).\n",
      "\n",
      "When using these images, please give credit to Olivetti Research Laboratory.\n",
      "A convenient reference is the face recognition work which uses some of\n",
      "these images:\n",
      "\n",
      " F. Samaria and A. Harter \n",
      "  \"Parameterisation of a stochastic model for human face identification\"\n",
      "  2nd IEEE Workshop on Applications of Computer Vision\n",
      "  December 1994, Sarasota (Florida).\n",
      "\n",
      "The paper is available via anonymous ftp from quince.cam-orl.co.uk and is\n",
      "stored in pub/users/fs/IEEE_workshop.ps.Z\n",
      "\n",
      "If you have any question, please email Ferdinando Samaria: fs@cam-orl.co.uk\n",
      "\n",
      "============================================================\n",
      "Dataset: S-CURVE\n",
      "Shape: data=(1000, 3), target=(1000,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: sklearn.datasets.samples_generator.make_s_curve\n",
      "\n",
      ">>> make_s_curve(1000, random_state=6502)\n",
      "\n",
      ">>> help(make_s_curve)\n",
      "\n",
      "Generate an S curve dataset.\n",
      "\n",
      "    Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n_samples : int, optional (default=100)\n",
      "        The number of sample points on the S curve.\n",
      "\n",
      "    noise : float, optional (default=0.0)\n",
      "        The standard deviation of the gaussian noise.\n",
      "\n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    X : array of shape [n_samples, 3]\n",
      "        The points.\n",
      "\n",
      "    t : array of shape [n_samples]\n",
      "        The univariate position of the sample according to the main dimension\n",
      "        of the points in the manifold.\n",
      "    \n",
      "============================================================\n",
      "Dataset: SHUTTLE-STATLOG\n",
      "Shape: data=(43500, 9), target=(43500,)\n",
      "============================================================\n",
      "\n",
      "Description of SHUTTLE Dataset (STATLOG VERSION)\n",
      "\n",
      "\n",
      "THIS DATASET SHOULD BE TACKLED BY TRAIN/TEST.\n",
      "\n",
      "\n",
      "NUMBER OF EXAMPLES\n",
      "\ttraining set     43500\n",
      "\ttest set         14500\n",
      "\n",
      "NUMBER OF ATTRIBUTES\n",
      "\t9\n",
      "\n",
      "The shuttle dataset contains 9 attributes all of which are numerical.\n",
      "The first one being time.  The last column is the class which has been \n",
      "coded as follows :\n",
      "        1       Rad Flow\n",
      "        2       Fpv Close\n",
      "        3       Fpv Open\n",
      "        4       High\n",
      "        5       Bypass\n",
      "        6       Bpv Close\n",
      "        7       Bpv Open\n",
      "        \n",
      "Approximately 80% of the data belongs to class 1. Therefore the default \n",
      "accuracy is about 80%. The aim here is to obtain an accuracy of \n",
      "99 - 99.9%.        \n",
      "\n",
      "\n",
      "Validation set:\n",
      "The examples in the original dataset were in time order, and this time order\n",
      "could presumably be relevant in classification.   However, this was not deemed\n",
      "relevant for StatLog purposes, so the order of the examples\n",
      " in the original dataset was randomised, and \n",
      "a portion of the original dataset removed for validation purposes.\n",
      "\n",
      "Acknowledgment:\n",
      "Thanks to Jason Catlett of Basser Department of Computer Science, \n",
      "University of Sydney, N.S.W., Australia for providing the shuttle dataset.  \n",
      "Thanks also to NASA for allowing us to use the shuttle datasets.\n",
      "        \n",
      "\n",
      "============================================================\n",
      "Dataset: SPHERE\n",
      "Shape: data=(1000, 3), target=(1000,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: src.data.synthetic.sample_sphere_surface\n",
      "\n",
      ">>> sample_sphere_surface(1000, random_state=6502)\n",
      "\n",
      ">>> help(sample_sphere_surface)\n",
      "\n",
      "Sample on the surface of a sphere\n",
      "\n",
      "    See Wolfram Sphere Point Picking\n",
      "    (Muller 1959, Marsaglia 1972)\n",
      "\n",
      "    Other ways to do this: http://www-alg.ist.hokudai.ac.jp/~jan/randsphere.pdf,\n",
      "    Use a very simple trick to color the points in a reasonable way\n",
      "    \n",
      "============================================================\n",
      "Dataset: SWISS-ROLL\n",
      "Shape: data=(1000, 3), target=(1000,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: sklearn.datasets.samples_generator.make_swiss_roll\n",
      "\n",
      ">>> make_swiss_roll(1000, noise=0.2, random_state=6502)\n",
      "\n",
      ">>> help(make_swiss_roll)\n",
      "\n",
      "Generate a swiss roll dataset.\n",
      "\n",
      "    Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n_samples : int, optional (default=100)\n",
      "        The number of sample points on the S curve.\n",
      "\n",
      "    noise : float, optional (default=0.0)\n",
      "        The standard deviation of the gaussian noise.\n",
      "\n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    X : array of shape [n_samples, 3]\n",
      "        The points.\n",
      "\n",
      "    t : array of shape [n_samples]\n",
      "        The univariate position of the sample according to the main dimension\n",
      "        of the points in the manifold.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The algorithm is from Marsland [1].\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    .. [1] S. Marsland, \"Machine Learning: An Algorithmic Perspective\",\n",
      "           Chapter 10, 2009.\n",
      "           http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py\n",
      "    \n",
      "============================================================\n",
      "Dataset: TWINPEAKS\n",
      "Shape: data=(3000, 3), target=(3000,)\n",
      "============================================================\n",
      "\n",
      "Synthetic data produced by: src.data.synthetic.synthetic_data\n",
      "\n",
      ">>> synthetic_data(kind='twinpeaks', n_points=3000, noise=0.05, random_state=6502)\n",
      "\n",
      ">>> help(synthetic_data)\n",
      "\n",
      "Make a synthetic dataset\n",
      "\n",
      "    A sample dataset generators in the style of sklearn's\n",
      "    `sample_generators`. This adds other functions found in the Matlab\n",
      "    toolkit for Dimensionality Reduction\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    kind: {'unit_cube', 'broken_swiss_roll', 'twinpeaks', 'difficult'}\n",
      "        The type of synthetic dataset\n",
      "    n_points : int, optional (default=1000)\n",
      "        The total number of points generated.\n",
      "    noise : double or None (default=None)\n",
      "        Standard deviation of Gaussian noise added to the data.\n",
      "    random_state : int, RandomState instance or None (default)\n",
      "        Determines random number generation for dataset shuffling and noise.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "    Returns\n",
      "    -------\n",
      "    X : array of shape [n_points, 2]\n",
      "        The generated samples.\n",
      "    y : array of shape [n_points]\n",
      "        The labels for class membership of each point.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "div = '=' * 60 + '\\n'\n",
    "for dataset_name in datasets.available_datasets():\n",
    "    dset = datasets.load_dataset(dataset_name)\n",
    "    print(f\"{div}Dataset: {dataset_name.upper()}\\n\"\n",
    "          f\"Shape: data={dset.data.shape}, target={dset.target.shape}\\n{div}\\n\"\n",
    "          f\"{dset.DESCR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ball',\n",
       " 'broken-swiss-roll',\n",
       " 'coil-100',\n",
       " 'coil-20',\n",
       " 'difficult',\n",
       " 'f-mnist',\n",
       " 'frey-faces',\n",
       " 'gaussian-blobs',\n",
       " 'helix',\n",
       " 'hiva',\n",
       " 'lvq-pak',\n",
       " 'mnist',\n",
       " 'orl-faces',\n",
       " 's-curve',\n",
       " 'shuttle-statlog',\n",
       " 'sphere',\n",
       " 'swiss-roll',\n",
       " 'twinpeaks']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.available_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dimension_reduction]",
   "language": "python",
   "name": "conda-env-dimension_reduction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
